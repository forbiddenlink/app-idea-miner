# App-Idea Miner üöÄ

> **Discover validated app opportunities from real user needs**

An intelligent opportunity detection platform that automatically collects, clusters, and analyzes "I wish there was an app..." style posts from across the web. Get evidence-backed insights on what people actually want to build.

[![License: MIT](https://img.shields.io/badge/License-MIT-blue.svg)](LICENSE)
[![Python 3.12](https://img.shields.io/badge/python-3.12-blue.svg)](https://www.python.org/downloads/)
[![PostgreSQL 16](https://img.shields.io/badge/postgresql-16-blue.svg)](https://www.postgresql.org/)
[![Redis 7](https://img.shields.io/badge/redis-7-red.svg)](https://redis.io/)

---

## ‚ú® Features

- **üîç Smart Ingestion:** Automatically fetches posts from RSS feeds and APIs
- **üß† AI-Powered Clustering:** Groups similar ideas using HDBSCAN + TF-IDF
- **üíé Evidence-Based:** Every opportunity backed by real user quotes
- **üìä Beautiful Analytics:** Modern dashboard with real-time updates
- **‚ö° Real-Time Updates:** WebSocket-powered live data
- **üéØ Opportunity Scoring:** Quality, sentiment, and trend analysis
- **üîß Extensible:** Easy to add new data sources

---

## üé¨ Quick Start

### Prerequisites

- Docker Desktop 4.0+ (with Docker Compose V2)
- Make (comes with macOS/Linux, Windows users can use WSL)
- 4GB RAM minimum
- 2GB free disk space

### Installation

```bash
# Clone the repository
git clone https://github.com/yourusername/app-idea-miner.git
cd app-idea-miner

# Copy environment configuration
cp .env.example .env

# Start all services
make dev
```

That's it! üéâ

The following services will be available:
- **Web UI:** http://localhost:3000
- **API:** http://localhost:8000
- **API Docs:** http://localhost:8000/docs
- **Flower (Celery Monitor):** http://localhost:5555
- **PostgreSQL:** localhost:5432
- **Redis:** localhost:6379

### First Run

```bash
# Load sample data (100+ curated app ideas)
make seed

# Wait 30 seconds for processing...

# Open the web UI
open http://localhost:3000
```

You should see 10-15 clusters with evidence links!

---

## üìñ Documentation

Comprehensive documentation is available in the [`docs/`](docs/) directory:

- **[PLAN.md](docs/PLAN.md)** - High-level development plan with phases
- **[ARCHITECTURE.md](docs/ARCHITECTURE.md)** - System architecture and tech stack
- **[SCHEMA.md](docs/SCHEMA.md)** - Database schema design
- **[API_SPEC.md](docs/API_SPEC.md)** - Complete API reference
- **[CLUSTERING.md](docs/CLUSTERING.md)** - Deep dive into clustering algorithm
- **[DATA_SOURCES.md](docs/DATA_SOURCES.md)** - How to add new sources
- **[DEPLOYMENT.md](docs/DEPLOYMENT.md)** - Production deployment guide
- **[TESTING.md](docs/TESTING.md)** - Testing strategy and guidelines

---

## üèóÔ∏è Architecture

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                        Data Sources                          ‚îÇ
‚îÇ  RSS Feeds ‚Ä¢ JSON APIs ‚Ä¢ Sample Data ‚Ä¢ (Future: Social APIs)‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                       ‚îÇ
                       ‚ñº
         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
         ‚îÇ  Ingestion (Celery)  ‚îÇ
         ‚îÇ  Dedupe ‚Ä¢ Enrich     ‚îÇ
         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                    ‚îÇ
         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
         ‚îÇ                      ‚îÇ
         ‚ñº                      ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Processing    ‚îÇ    ‚îÇ  Clustering    ‚îÇ
‚îÇ  NLP ‚Ä¢ Extract ‚îÇ    ‚îÇ  HDBSCAN ‚Ä¢ ML  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ                     ‚îÇ
         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                    ‚îÇ
                    ‚ñº
         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
         ‚îÇ  PostgreSQL 16   ‚îÇ
         ‚îÇ  Redis 7         ‚îÇ
         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                    ‚îÇ
         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
         ‚îÇ                     ‚îÇ
         ‚ñº                     ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  FastAPI       ‚îÇ    ‚îÇ  React + Vite  ‚îÇ
‚îÇ  REST + WS     ‚îÇ‚óÑ‚îÄ‚îÄ‚îÄ‚î§  Modern UI     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Tech Stack

**Backend:**
- Python 3.12
- FastAPI (async API)
- Celery (background tasks)
- SQLAlchemy (ORM)
- Alembic (migrations)

**Data Science:**
- scikit-learn (TF-IDF, clustering)
- HDBSCAN (density-based clustering)
- NLTK (text processing)
- VADER (sentiment analysis)

**Frontend:**
- React 18 + TypeScript
- Vite (build tool)
- Tailwind CSS (styling)
- Recharts (visualizations)
- Zustand (state management)

**Infrastructure:**
- PostgreSQL 16 (persistence)
- Redis 7 (queue + cache)
- Docker Compose (orchestration)
- Nginx (reverse proxy, future)

---

## üõ†Ô∏è Development Commands

### Core Commands

```bash
# Start all services (API, Worker, DB, Redis, Web UI)
make dev

# Stop all services
make down

# View logs (all services)
make logs

# View logs (specific service)
make logs-api
make logs-worker
make logs-web
```

### Database Commands

```bash
# Run pending migrations
make migrate

# Create new migration
make migration name=add_user_table

# Reset database (WARNING: deletes all data)
make db-reset

# Open database shell
make db-shell
```

### Data Commands

```bash
# Load sample data
make seed

# Trigger ingestion manually
make ingest

# Run clustering
make cluster

# Clear all data
make clean-data
```

### Testing Commands

```bash
# Run all tests
make test

# Run with coverage
make test-coverage

# Run specific test file
make test-file path=tests/test_clustering.py

# Lint code
make lint

# Format code
make format
```

### Utility Commands

```bash
# Enter API container shell
make shell-api

# Enter worker container shell
make shell-worker

# View cluster sizes
make stats

# Backup database
make backup

# Full cleanup (containers, volumes, cache)
make clean
```

---

## üìÅ Project Structure

```
app-idea-miner/
‚îú‚îÄ‚îÄ apps/
‚îÇ   ‚îú‚îÄ‚îÄ api/                    # FastAPI backend
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ app/
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ main.py
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ routes/         # API endpoints
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ models/         # SQLAlchemy models
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ schemas/        # Pydantic schemas
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ services/       # Business logic
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ tests/
‚îÇ   ‚îú‚îÄ‚îÄ worker/                 # Celery background tasks
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ tasks/
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ ingestion.py
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ processing.py
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ clustering.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ celery_app.py
‚îÇ   ‚îî‚îÄ‚îÄ web/                    # React frontend
‚îÇ       ‚îú‚îÄ‚îÄ src/
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ components/     # Reusable UI components
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ pages/          # Route pages
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ hooks/          # Custom React hooks
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ services/       # API client
‚îÇ       ‚îÇ   ‚îî‚îÄ‚îÄ App.tsx
‚îÇ       ‚îî‚îÄ‚îÄ package.json
‚îú‚îÄ‚îÄ packages/
‚îÇ   ‚îî‚îÄ‚îÄ core/                   # Shared Python logic
‚îÇ       ‚îú‚îÄ‚îÄ models.py           # Database models
‚îÇ       ‚îú‚îÄ‚îÄ clustering.py       # Clustering engine
‚îÇ       ‚îú‚îÄ‚îÄ nlp.py              # Text processing
‚îÇ       ‚îî‚îÄ‚îÄ dedupe.py           # Deduplication
‚îú‚îÄ‚îÄ infra/
‚îÇ   ‚îú‚îÄ‚îÄ docker-compose.yml
‚îÇ   ‚îú‚îÄ‚îÄ Dockerfile.api
‚îÇ   ‚îú‚îÄ‚îÄ Dockerfile.worker
‚îÇ   ‚îî‚îÄ‚îÄ postgres/
‚îÇ       ‚îî‚îÄ‚îÄ init.sql
‚îú‚îÄ‚îÄ migrations/                 # Alembic migrations
‚îÇ   ‚îú‚îÄ‚îÄ versions/
‚îÇ   ‚îî‚îÄ‚îÄ env.py
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îú‚îÄ‚îÄ sample_posts.json       # Seed data (100+ ideas)
‚îÇ   ‚îî‚îÄ‚îÄ fixtures/
‚îú‚îÄ‚îÄ docs/                       # Documentation
‚îÇ   ‚îú‚îÄ‚îÄ PLAN.md
‚îÇ   ‚îú‚îÄ‚îÄ ARCHITECTURE.md
‚îÇ   ‚îú‚îÄ‚îÄ API_SPEC.md
‚îÇ   ‚îî‚îÄ‚îÄ ...
‚îú‚îÄ‚îÄ tests/
‚îÇ   ‚îú‚îÄ‚îÄ unit/
‚îÇ   ‚îú‚îÄ‚îÄ integration/
‚îÇ   ‚îî‚îÄ‚îÄ conftest.py
‚îú‚îÄ‚îÄ Makefile                    # Development commands
‚îú‚îÄ‚îÄ README.md                   # This file
‚îú‚îÄ‚îÄ .env.example                # Environment template
‚îú‚îÄ‚îÄ .gitignore
‚îî‚îÄ‚îÄ docker-compose.yml
```

---

## üîß Configuration

### Environment Variables

Create a `.env` file in the root directory (copy from `.env.example`):

```bash
# Database
DATABASE_URL=postgresql://postgres:postgres@postgres:5432/appideas
POSTGRES_USER=postgres
POSTGRES_PASSWORD=postgres
POSTGRES_DB=appideas

# Redis
REDIS_URL=redis://redis:6379/0

# API
API_HOST=0.0.0.0
API_PORT=8000
API_WORKERS=4
CORS_ORIGINS=http://localhost:3000,http://localhost:5173
LOG_LEVEL=info

# Worker
CELERY_BROKER_URL=redis://redis:6379/0
CELERY_RESULT_BACKEND=redis://redis:6379/1
CELERY_WORKERS=2

# Web UI
VITE_API_URL=http://localhost:8000
VITE_WS_URL=ws://localhost:8000

# Data Sources
RSS_FEEDS=https://hnrss.org/newest
FETCH_INTERVAL_HOURS=6

# Clustering
MIN_CLUSTER_SIZE=3
MAX_FEATURES=500
RECLUSTER_THRESHOLD=100
```

---

## üöÄ Usage Examples

### Example 1: View Top Clusters

```bash
curl http://localhost:8000/api/v1/clusters?sort_by=size&limit=5
```

**Response:**
```json
{
  "data": {
    "clusters": [
      {
        "id": "...",
        "label": "Book Reading & Progress Tracking",
        "keywords": ["reading", "books", "progress", "tracking"],
        "idea_count": 23,
        "avg_sentiment": 0.58,
        "trend_score": 0.82
      }
    ]
  }
}
```

### Example 2: Search for Ideas

```bash
curl "http://localhost:8000/api/v1/ideas/search?q=budget+tracking"
```

### Example 3: Trigger Ingestion

```bash
curl -X POST http://localhost:8000/api/v1/jobs/ingest
```

### Example 4: Real-Time Updates (JavaScript)

```javascript
const ws = new WebSocket('ws://localhost:8000/ws/updates');

ws.onmessage = (event) => {
  const message = JSON.parse(event.data);
  
  if (message.event === 'cluster_created') {
    console.log('New opportunity:', message.data.label);
  }
};
```

---

## üé® UI Screenshots

### Dashboard
![Dashboard](docs/assets/dashboard.png)
*Overview with stats, trending clusters, and recent activity*

### Cluster Detail
![Cluster Detail](docs/assets/cluster-detail.png)
*Evidence links, keywords, sentiment, and trends*

### Analytics
![Analytics](docs/assets/analytics.png)
*Time-series charts, domain breakdown, sentiment distribution*

---

## üß™ Testing

### Run Test Suite

```bash
# All tests
make test

# With coverage report
make test-coverage

# Specific module
pytest tests/unit/test_clustering.py -v
```

### Test Coverage

Current coverage: **85%**

Key areas:
- ‚úÖ Clustering algorithm: 92%
- ‚úÖ Deduplication logic: 88%
- ‚úÖ Text processing: 85%
- ‚úÖ API endpoints: 80%
- ‚ö†Ô∏è Worker tasks: 70% (target: 80%)

---

## üîç How It Works

### 1. Ingestion

The system fetches posts from:
- **RSS Feeds:** Hacker News, Product Hunt (configurable)
- **Sample Data:** 100+ curated examples in `data/sample_posts.json`
- **Future:** Reddit API, Twitter API, GitHub Issues

Posts are deduplicated by URL hash and content fingerprinting.

### 2. Processing

Each post is analyzed to extract:
- **Problem Statements:** "I wish there was an app for X"
- **Sentiment:** Positive, neutral, or negative (VADER)
- **Emotions:** Frustration, hope, urgency levels
- **Domain:** Productivity, health, finance, etc.
- **Quality Score:** Specificity + actionability (0-1)

### 3. Clustering

Similar ideas are grouped using:
- **TF-IDF Vectorization:** Convert text to numerical features
- **HDBSCAN:** Density-based clustering (auto-detects cluster count)
- **Keyword Extraction:** Top 10 terms per cluster
- **Label Generation:** Human-readable cluster names

**Example Cluster:**
```
Label: "Budget & Expense Tracking"
Keywords: [budget, expense, tracking, finance, spending, ...]
Ideas: 23
Avg Sentiment: 0.65 (positive)
Trend: 0.82 (hot!)
```

### 4. API & UI

- **FastAPI** serves REST endpoints and WebSockets
- **React UI** displays clusters, ideas, and analytics
- **Real-time updates** via WebSocket push notifications

---

## üìä Sample Data

The `data/sample_posts.json` contains 100+ curated "I wish there was an app" examples across domains:

- **Productivity:** Task managers, note-taking, habit trackers
- **Health:** Fitness, nutrition, mental health
- **Finance:** Budgeting, investing, expense tracking
- **Social:** Networking, dating, community building
- **Education:** Learning platforms, tutoring, skill development
- **Entertainment:** Media discovery, recommendations, gaming

Load it with:
```bash
make seed
```

---

## üåü Adding New Data Sources

See [DATA_SOURCES.md](docs/DATA_SOURCES.md) for detailed instructions.

**Quick Example (RSS Feed):**

1. Edit `.env`:
```bash
RSS_FEEDS=https://hnrss.org/newest,https://example.com/feed.xml
```

2. Restart worker:
```bash
docker-compose restart worker
```

3. Trigger ingestion:
```bash
make ingest
```

**Custom Source (API):**

Create a new fetcher in `apps/worker/tasks/ingestion.py`:

```python
@celery_app.task
def fetch_from_custom_api():
    response = httpx.get('https://api.example.com/ideas')
    posts = response.json()
    
    for post in posts:
        save_raw_post(
            url=post['url'],
            title=post['title'],
            content=post['body'],
            source='custom_api',
            published_at=post['created_at']
        )
```

---

## üöß Roadmap

### MVP (Current)
- [x] RSS feed ingestion
- [x] Sample data loader
- [x] HDBSCAN clustering
- [x] FastAPI backend
- [x] React UI
- [x] Real-time updates
- [x] Docker Compose setup

### Phase 2 (Next 2 months)
- [ ] Reddit API integration
- [ ] Twitter/X API integration
- [ ] User authentication
- [ ] Cluster voting/feedback
- [ ] Email alerts for hot clusters
- [ ] Export to PDF/CSV

### Phase 3 (Q2 2026)
- [ ] Competition analysis (auto-detect existing apps)
- [ ] Market sizing estimates
- [ ] GPT-4 cluster descriptions
- [ ] Multi-language support
- [ ] Public API with keys
- [ ] Team collaboration features

### Long-term
- [ ] Mobile app (React Native)
- [ ] Kubernetes deployment
- [ ] Graph database (relationships)
- [ ] ML model fine-tuning
- [ ] Monetization (premium tier)

---

## üêõ Troubleshooting

### Containers won't start

```bash
# Check if ports are in use
lsof -i :8000  # API
lsof -i :5432  # PostgreSQL
lsof -i :6379  # Redis

# Kill conflicting processes or change ports in .env
```

### Database connection error

```bash
# Ensure PostgreSQL is running
docker-compose ps postgres

# Check logs
docker-compose logs postgres

# Restart
docker-compose restart postgres
```

### No clusters appearing

```bash
# Check if data was seeded
docker-compose exec api python -c "from app.models import RawPost; from app.database import SessionLocal; db = SessionLocal(); print(db.query(RawPost).count())"

# Manually trigger clustering
curl -X POST http://localhost:8000/api/v1/jobs/recluster

# Check worker logs
docker-compose logs worker -f
```

### Slow clustering

```bash
# Reduce data size for testing
# Edit data/sample_posts.json (keep first 20 entries)

# Or adjust parameters in .env
MIN_CLUSTER_SIZE=5  # Larger = faster but coarser
```

---

## üìÑ License

MIT License - see [LICENSE](LICENSE) file for details.

---

## ü§ù Contributing

We welcome contributions! Please see [CONTRIBUTING.md](CONTRIBUTING.md) for guidelines.

**Quick steps:**
1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing`)
3. Commit your changes (`git commit -am 'Add amazing feature'`)
4. Push to the branch (`git push origin feature/amazing`)
5. Open a Pull Request

---

## üí¨ Community & Support

- **Issues:** [GitHub Issues](https://github.com/yourusername/app-idea-miner/issues)
- **Discussions:** [GitHub Discussions](https://github.com/yourusername/app-idea-miner/discussions)
- **Email:** support@app-idea-miner.com
- **Twitter:** [@AppIdeaMiner](https://twitter.com/AppIdeaMiner)

---

## üôè Acknowledgments

Inspired by:
- **Brandwatch** - Social listening and analytics
- **ProductGapHunt** - Idea validation tools
- **Academic research** on app review mining and NLP

Built with love using:
- FastAPI, scikit-learn, HDBSCAN, React, and many more amazing open-source tools

---

## üìà Statistics

- **Lines of Code:** ~15,000
- **Test Coverage:** 85%
- **Docker Images:** 4 (API, Worker, Web, Postgres)
- **API Endpoints:** 25+
- **UI Components:** 30+
- **Supported Data Sources:** 3 (RSS, JSON, Sample)

---

## üéØ Goals

Our mission is to **democratize opportunity discovery** by making it easy for anyone to:
- Identify real user needs
- Validate ideas with evidence
- Understand market demand
- Build products people actually want

**Let's build the future together!** üöÄ

---

Made with ‚ù§Ô∏è by [Your Name](https://github.com/yourusername)
