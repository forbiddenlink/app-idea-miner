# âš¡ Quick Start: Implementing Research Recommendations

**Time to implement:** 2-3 days for P0 items  
**Prerequisite:** Read [RESEARCH_RECOMMENDATIONS_2025.md](./RESEARCH_RECOMMENDATIONS_2025.md)

---

## ðŸŽ¯ Priority 0: Must Do Before Building

### 1. Switch to UV (30 minutes)

```bash
# Install UV
curl -LsSf https://astral.sh/uv/install.sh | sh

# Create root pyproject.toml
cat > pyproject.toml << 'EOF'
[tool.uv.workspace]
members = ["apps/*", "packages/*"]

[tool.uv]
dev-dependencies = [
    "pytest>=8.0.0",
    "pytest-asyncio>=0.24.0",
    "ruff>=0.7.0",
    "pre-commit>=4.0.0",
]
EOF

# Create lock file
uv lock

# Remove old requirements.txt files
rm apps/*/requirements.txt
```

### 2. Create Service Layer Structure (1 hour)

```bash
# Create service directories
mkdir -p apps/api/app/services
touch apps/api/app/services/__init__.py
touch apps/api/app/services/cluster_service.py
touch apps/api/app/services/idea_service.py
touch apps/api/app/services/analytics_service.py
```

**Template for services:**

```python
# apps/api/app/services/cluster_service.py
from typing import List, Optional
from uuid import UUID
from sqlalchemy.ext.asyncio import AsyncSession
from sqlalchemy import select
from ..models import Cluster

class ClusterService:
    def __init__(self, db: AsyncSession):
        self.db = db
    
    async def get_all(self, limit: int = 20, offset: int = 0) -> List[Cluster]:
        """Get all clusters with pagination"""
        result = await self.db.execute(
            select(Cluster)
            .order_by(Cluster.idea_count.desc())
            .limit(limit)
            .offset(offset)
        )
        return result.scalars().all()
    
    async def get_by_id(self, cluster_id: UUID) -> Optional[Cluster]:
        """Get single cluster"""
        result = await self.db.execute(
            select(Cluster).where(Cluster.id == cluster_id)
        )
        return result.scalar_one_or_none()
```

### 3. Fix Database Connection (30 minutes)

```python
# apps/api/app/database.py
from sqlalchemy.ext.asyncio import create_async_engine, async_sessionmaker, AsyncSession
import os

# âœ… CRITICAL: Use asyncpg driver
DATABASE_URL = os.getenv("DATABASE_URL", "postgresql://postgres:postgres@localhost/appideas")
ASYNC_DATABASE_URL = DATABASE_URL.replace('postgresql://', 'postgresql+asyncpg://')

engine = create_async_engine(
    ASYNC_DATABASE_URL,
    pool_size=10,
    max_overflow=20,
    pool_timeout=30,
    pool_recycle=1800,
    pool_pre_ping=True,
    echo=False,
)

SessionLocal = async_sessionmaker(
    engine,
    class_=AsyncSession,
    expire_on_commit=False,
    autoflush=False,
    autocommit=False
)

async def get_db():
    """Dependency for FastAPI routes"""
    async with SessionLocal() as session:
        try:
            yield session
            await session.commit()
        except Exception:
            await session.rollback()
            raise
        finally:
            await session.close()
```

### 4. Update Docker Compose (1 hour)

```yaml
# docker-compose.yml
version: '3.9'

x-common-env: &common-env
  DATABASE_URL: postgresql://postgres:postgres@postgres:5432/appideas
  REDIS_URL: redis://redis:6379/0

services:
  postgres:
    image: postgres:16-alpine
    environment:
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: postgres
      POSTGRES_DB: appideas
    volumes:
      - postgres_data:/var/lib/postgresql/data
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U postgres"]
      interval: 10s
      timeout: 5s
      retries: 5
    restart: unless-stopped

  redis:
    image: redis:7-alpine
    command: redis-server --maxmemory 512mb --maxmemory-policy allkeys-lru
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 3
    restart: unless-stopped

  api:
    build:
      context: .
      dockerfile: infra/Dockerfile.api
    environment:
      <<: *common-env
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
    ports:
      - "8000:8000"
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
    restart: unless-stopped

  worker:
    build:
      context: .
      dockerfile: infra/Dockerfile.worker
    environment:
      <<: *common-env
      CELERY_BROKER_URL: redis://redis:6379/0
      CELERY_RESULT_BACKEND: redis://redis:6379/1
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
    restart: unless-stopped

  flower:
    image: mher/flower:2.0
    command: celery --broker=redis://redis:6379/0 flower --port=5555
    ports:
      - "5555:5555"
    depends_on:
      - redis
    restart: unless-stopped

volumes:
  postgres_data:

networks:
  default:
    name: appideas_network
```

### 5. Create Proper Dockerfiles (30 minutes)

```dockerfile
# infra/Dockerfile.api
FROM python:3.12-slim

# Install UV
COPY --from=ghcr.io/astral-sh/uv:latest /uv /usr/local/bin/uv

WORKDIR /app

# Copy dependency files
COPY pyproject.toml uv.lock ./
COPY packages packages
COPY apps/api apps/api

# Install dependencies
RUN uv sync --frozen --no-dev

# Non-root user for security
RUN useradd -m -u 1000 appuser && chown -R appuser:appuser /app
USER appuser

# Health check
HEALTHCHECK --interval=30s --timeout=10s --retries=3 \
  CMD curl -f http://localhost:8000/health || exit 1

CMD ["uv", "run", "uvicorn", "apps.api.app.main:app", "--host", "0.0.0.0", "--port", "8000"]
```

```dockerfile
# infra/Dockerfile.worker
FROM python:3.12-slim

COPY --from=ghcr.io/astral-sh/uv:latest /uv /usr/local/bin/uv

WORKDIR /app

COPY pyproject.toml uv.lock ./
COPY packages packages
COPY apps/worker apps/worker

RUN uv sync --frozen --no-dev

RUN useradd -m -u 1000 appuser && chown -R appuser:appuser /app
USER appuser

CMD ["uv", "run", "celery", "-A", "apps.worker.celery_app", "worker", "--loglevel=info"]
```

---

## ðŸ§ª Testing Your Setup

```bash
# 1. Verify UV is working
uv --version

# 2. Install dependencies
uv sync

# 3. Start services
docker-compose up -d

# 4. Check health
curl http://localhost:8000/health
curl http://localhost:5555  # Flower UI

# 5. View logs
docker-compose logs -f api
docker-compose logs -f worker

# 6. Run tests
uv run pytest
```

---

## ðŸ“‹ Checklist

Before moving to Phase 1 implementation:

- [ ] UV installed and `uv.lock` file created
- [ ] All services have `pyproject.toml` with dependencies
- [ ] Service layer structure created
- [ ] Database uses `postgresql+asyncpg://` URL
- [ ] Docker Compose has health checks
- [ ] `docker-compose up` starts all services
- [ ] API health check returns 200
- [ ] Flower UI accessible at :5555
- [ ] Dockerfiles use UV for dependency management
- [ ] Non-root user in Docker containers

---

## ðŸŽ¯ Next: Priority 1 Items

After P0 is complete:

1. **PostgreSQL JSONB indexes** (see RESEARCH_RECOMMENDATIONS_2025.md Â§4)
2. **WebSocket ConnectionManager** (see Â§5)
3. **BERTopic clustering** (see Â§2)

---

## ðŸ†˜ Troubleshooting

**UV not found:**
```bash
curl -LsSf https://astral.sh/uv/install.sh | sh
source ~/.bashrc  # or ~/.zshrc
```

**Docker build fails:**
```bash
# Clear cache and rebuild
docker-compose down -v
docker-compose build --no-cache
docker-compose up
```

**Database connection error:**
```bash
# Check if PostgreSQL is ready
docker-compose logs postgres | grep "ready"

# Verify connection string
docker-compose exec api env | grep DATABASE_URL
```

**Worker not processing tasks:**
```bash
# Check Celery connection
docker-compose exec worker uv run celery -A apps.worker.celery_app inspect ping

# Check Redis
docker-compose exec redis redis-cli ping
```

---

## ðŸ“š Key Files Reference

| File | Purpose |
|------|---------|
| `pyproject.toml` (root) | Workspace definition, dev dependencies |
| `apps/*/pyproject.toml` | Service-specific dependencies |
| `uv.lock` | Locked dependencies (commit this!) |
| `docker-compose.yml` | Production-ready orchestration |
| `apps/api/app/database.py` | Async SQLAlchemy setup |
| `apps/api/app/services/` | Business logic layer |

---

**Time Investment:**  
âœ… P0 Setup: **3-4 hours**  
âœ… Validation: **30 minutes**  
âœ… Total: **Half a day**

**ROI:**  
ðŸš€ **10x faster builds**  
ðŸ›¡ï¸ **Production-ready foundation**  
ðŸ“ˆ **Maintainable architecture**

---

Ready to build! ðŸŽ‰
